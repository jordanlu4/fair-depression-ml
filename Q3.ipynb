{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7d9e322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "167bb12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined shape: (16681, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>okay</td>\n",
       "      <td>423_Transcript.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and please</td>\n",
       "      <td>423_Transcript.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>423_Transcript.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feeling well</td>\n",
       "      <td>423_Transcript.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>where are you from originally Los Angeles the...</td>\n",
       "      <td>423_Transcript.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>people</td>\n",
       "      <td>423_Transcript.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>diversity and</td>\n",
       "      <td>423_Transcript.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>various entertainment and activities</td>\n",
       "      <td>423_Transcript.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fickle weather</td>\n",
       "      <td>423_Transcript.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>traffic and litter</td>\n",
       "      <td>423_Transcript.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text         source_file\n",
       "0                                               okay  423_Transcript.csv\n",
       "1                                         and please  423_Transcript.csv\n",
       "2                                                yes  423_Transcript.csv\n",
       "3                                       feeling well  423_Transcript.csv\n",
       "4   where are you from originally Los Angeles the...  423_Transcript.csv\n",
       "5                                             people  423_Transcript.csv\n",
       "6                                      diversity and  423_Transcript.csv\n",
       "7               various entertainment and activities  423_Transcript.csv\n",
       "8                                     fickle weather  423_Transcript.csv\n",
       "9                                 traffic and litter  423_Transcript.csv"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Working code to read in every .csv line by line\n",
    "    This inclues ONLY E-DAIC_Transcripts NOT TranscriptsOld, just remove root == \"data/TranscriptsOld\" if we want to change that\n",
    "\"\"\"\n",
    "\n",
    "all_csvs = []\n",
    "for root, dirs, files in os.walk(\"data\"):\n",
    "    for file in files:\n",
    "        if not file.endswith(\".csv\") or file == \"test.csv\" or root == \"data/TranscriptsOld\":\n",
    "            continue  # ignore .xlsx and test.csv and old transcripts\n",
    "        full_path = os.path.join(root, file)\n",
    "        df = pd.read_csv(full_path, engine='python', on_bad_lines='skip')\n",
    "        df['source_file'] = file # Which conversation (ie) xxx_Transcript.csv\n",
    "        all_csvs.append(df)\n",
    "\n",
    "combined_df = pd.concat(all_csvs, ignore_index=True)\n",
    "\n",
    "print(\"Combined shape:\", combined_df.shape)\n",
    "combined_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef3d4082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Partic#</th>\n",
       "      <th>Condition</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Participant Number</td>\n",
       "      <td>Condition</td>\n",
       "      <td>What is your gender?</td>\n",
       "      <td>What is your race?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>302</td>\n",
       "      <td>WoZ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>303</td>\n",
       "      <td>WoZ</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>304</td>\n",
       "      <td>WoZ</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>305</td>\n",
       "      <td>WoZ</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Partic#  Condition                gender                race\n",
       "0  Participant Number  Condition  What is your gender?  What is your race?\n",
       "1                 302        WoZ                     1                   1\n",
       "2                 303        WoZ                     2                   1\n",
       "3                 304        WoZ                     2                   1\n",
       "4                 305        WoZ                     1                   4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    I think we only want this file The other one has things that we dont need for our work. \n",
    "\"\"\"\n",
    "df2 = pd.read_excel(\"data/DAIC demographic data.xlsx\", sheet_name=\"Interview_Data\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa328cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>Condition</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>okay</td>\n",
       "      <td>423</td>\n",
       "      <td>WoZ</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and please</td>\n",
       "      <td>423</td>\n",
       "      <td>WoZ</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>423</td>\n",
       "      <td>WoZ</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feeling well</td>\n",
       "      <td>423</td>\n",
       "      <td>WoZ</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>where are you from originally Los Angeles the...</td>\n",
       "      <td>423</td>\n",
       "      <td>WoZ</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>people</td>\n",
       "      <td>423</td>\n",
       "      <td>WoZ</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>diversity and</td>\n",
       "      <td>423</td>\n",
       "      <td>WoZ</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>various entertainment and activities</td>\n",
       "      <td>423</td>\n",
       "      <td>WoZ</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fickle weather</td>\n",
       "      <td>423</td>\n",
       "      <td>WoZ</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>traffic and litter</td>\n",
       "      <td>423</td>\n",
       "      <td>WoZ</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text participant_id Condition  \\\n",
       "0                                               okay            423       WoZ   \n",
       "1                                         and please            423       WoZ   \n",
       "2                                                yes            423       WoZ   \n",
       "3                                       feeling well            423       WoZ   \n",
       "4   where are you from originally Los Angeles the...            423       WoZ   \n",
       "5                                             people            423       WoZ   \n",
       "6                                      diversity and            423       WoZ   \n",
       "7               various entertainment and activities            423       WoZ   \n",
       "8                                     fickle weather            423       WoZ   \n",
       "9                                 traffic and litter            423       WoZ   \n",
       "\n",
       "  gender race  \n",
       "0      2    7  \n",
       "1      2    7  \n",
       "2      2    7  \n",
       "3      2    7  \n",
       "4      2    7  \n",
       "5      2    7  \n",
       "6      2    7  \n",
       "7      2    7  \n",
       "8      2    7  \n",
       "9      2    7  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Here we merge the text (from the csv) with the patient information from the xlsx\n",
    "    As we see from the assert this does not add or drop any rows but we do prune the cols to get nice df to work with from here\n",
    "\"\"\"\n",
    "combined_df['participant_id'] = combined_df['source_file'].str.extract(r\"(\\d+)_Transcript\\.csv\")\n",
    "combined_df.head()\n",
    "df2['participant_id'] = df2['Partic#'].astype(str).str.strip()\n",
    "merged_df = pd.merge(combined_df, df2, on='participant_id', how='left')\n",
    "merged_df = merged_df.drop(columns=['Partic#', 'source_file'])\n",
    "assert(combined_df.shape[0] == merged_df.shape[0])\n",
    "merged_df.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a91d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>Text</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>386</td>\n",
       "      <td>might have pulled something that  I'm going to...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>WoZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>387</td>\n",
       "      <td>when she's done she'll let you know  alrighty ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>WoZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>388</td>\n",
       "      <td>are you okay with  yes  doing all right  from ...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>WoZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>389</td>\n",
       "      <td>and please  are you okay  sure  I'm okay  smal...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>WoZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>390</td>\n",
       "      <td>and now she's going to chat with you for a bit...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>WoZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id                                               Text race  \\\n",
       "0            386  might have pulled something that  I'm going to...    3   \n",
       "1            387  when she's done she'll let you know  alrighty ...    1   \n",
       "2            388  are you okay with  yes  doing all right  from ...    4   \n",
       "3            389  and please  are you okay  sure  I'm okay  smal...    1   \n",
       "4            390  and now she's going to chat with you for a bit...    3   \n",
       "\n",
       "  gender Condition  \n",
       "0      2       WoZ  \n",
       "1      1       WoZ  \n",
       "2      1       WoZ  \n",
       "3      1       WoZ  \n",
       "4      1       WoZ  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    We amalgamate all the text for each 190 participants \n",
    "    \"df\" is now the working data frame \n",
    "\"\"\"\n",
    "df = merged_df.groupby('participant_id').agg({\n",
    "    'Text': ' '.join,        \n",
    "    'race': 'first',\n",
    "    'gender': 'first',\n",
    "    'Condition': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef362f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 210959\n",
      "Unique Words: 9348\n",
      "Top 10 most common words: [('I', 12774), ('and', 7208), ('to', 6299), ('the', 5428), ('a', 5166), ('that', 3927), ('you', 3782), ('of', 3525), ('my', 3474), ('it', 2779)]\n"
     ]
    }
   ],
   "source": [
    "# Just a quick glance at the data\n",
    "all_text = ' '.join(df['Text'].tolist())\n",
    "words = all_text.split()\n",
    "unique_words = set(words)\n",
    "word_count = Counter(words)\n",
    "print(\"Total words:\", len(words))\n",
    "print(\"Unique Words:\", len(unique_words))\n",
    "print(\"Top 10 most common words:\", word_count.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54dec05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing m = 50 features\n",
      "Testing m = 100 features\n",
      "Testing m = 300 features\n",
      "Testing m = 500 features\n",
      "Testing m = 1000 features\n",
      "Testing m = 7083 features\n",
      "\n",
      "Tree Results:\n",
      "      m  accuracy  balanced_accuracy\n",
      "0    50  0.527833           0.333283\n",
      "1   100  0.548768           0.352348\n",
      "2   300  0.626355           0.435303\n",
      "3   500  0.750246           0.515101\n",
      "4  1000  0.764039           0.517929\n",
      "5  7083  0.604680           0.391742\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    This code trains a Random Forest Classifier to predict the race of a participant based on the words they used.\n",
    "    We use the chi^2 metric to select the m most relevant words for our prediction:  selector = SelectKBest(score_func=chi2, k=m)\n",
    "    We slit the data into 5 partitions: five_fold_spit = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    Then we use a random forest classifier with 100 trees to predict the race of the participant based on their diction\n",
    "    The best m is m = 1000 with accuracy of 0.764039, if we presume random guessing between 3 classes would achive 33% accuracy, this is meaningfully better\n",
    "\n",
    "    * Note * The actual number of unique words according the classification library is 7083, this is because of case sensitivity and other ways the library drops words\n",
    "\"\"\"\n",
    "# Only look at the races we are considering --> 1: White, 2: Black, 3: Hispanic\n",
    "df_clean = df[df['race'].isin([1, 2, 3])]  \n",
    "df_clean = df_clean.reset_index(drop=True)\n",
    "\n",
    "X_text = df_clean['Text']\n",
    "y = df_clean['race'].astype(int)  \n",
    "\n",
    "# Vectorize the text\n",
    "vectorizer = TfidfVectorizer(max_features=10000, stop_words='english')\n",
    "X_vect = vectorizer.fit_transform(X_text)\n",
    "\n",
    "results = []\n",
    "\n",
    "m_values = [50, 100, 300, 500, 1000, 7083]\n",
    "for m in m_values:\n",
    "    print(f\"Testing m = {m} features\")\n",
    "    \n",
    "    # Feature selection using chi2\n",
    "    selector = SelectKBest(score_func=chi2, k=m)\n",
    "    X_selected = selector.fit_transform(X_vect, y)\n",
    "    \n",
    "    # Cross-validation setup\n",
    "    five_fold_spit = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    accs = []\n",
    "    bal_accs = []\n",
    "    \n",
    "    for train_idx, test_idx in five_fold_spit.split(X_selected, y):\n",
    "        X_train, X_test = X_selected[train_idx], X_selected[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        # Train Random Forest\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Store metrics\n",
    "        accs.append(accuracy_score(y_test, y_pred))\n",
    "        bal_accs.append(balanced_accuracy_score(y_test, y_pred))\n",
    "\n",
    "    results.append({\n",
    "        'm': m,\n",
    "        'accuracy': np.mean(accs),\n",
    "        'balanced_accuracy': np.mean(bal_accs)\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nTree Results:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88e7d952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing m = 50 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminapelman/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/benjaminapelman/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/benjaminapelman/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/benjaminapelman/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing m = 100 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminapelman/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/benjaminapelman/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/benjaminapelman/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/benjaminapelman/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/benjaminapelman/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing m = 300 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminapelman/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/benjaminapelman/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/benjaminapelman/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/benjaminapelman/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/benjaminapelman/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing m = 500 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminapelman/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/benjaminapelman/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/benjaminapelman/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/benjaminapelman/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/benjaminapelman/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing m = 1000 features\n",
      "Testing m = 7083 features\n",
      "\n",
      "Deep Learning Results:\n",
      "      m  accuracy  balanced_accuracy\n",
      "0    50  0.555665           0.350227\n",
      "1   100  0.548768           0.346061\n",
      "2   300  0.633005           0.435202\n",
      "3   500  0.854187           0.599217\n",
      "4  1000  0.930788           0.650000\n",
      "5  7083  0.652956           0.438030\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Pretty much the same here, only we use MLPClassifier this time, just a standard mpl network\n",
    "    We get a really good accuracy at m = 1000 of 0.930788\n",
    "\"\"\"\n",
    "\n",
    "df_clean = df[df['race'].isin([1, 2, 3])].reset_index(drop=True)\n",
    "X_text = df_clean['Text']\n",
    "y = df_clean['race'].astype(int)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=10000, stop_words='english')\n",
    "X_vect = vectorizer.fit_transform(X_text)\n",
    "\n",
    "m_values = [50, 100, 300, 500, 1000, 7083]\n",
    "results = []\n",
    "\n",
    "for m in m_values:\n",
    "    print(f\"Testing m = {m} features\")\n",
    "\n",
    "    selector = SelectKBest(score_func=chi2, k=m)\n",
    "    X_selected = selector.fit_transform(X_vect, y)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    accs = []\n",
    "    bal_accs = []\n",
    "\n",
    "    for train_idx, test_idx in skf.split(X_selected, y):\n",
    "        X_train, X_test = X_selected[train_idx], X_selected[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        model = MLPClassifier(hidden_layer_sizes=(100), max_iter=500, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Store metrics\n",
    "        accs.append(accuracy_score(y_test, y_pred))\n",
    "        bal_accs.append(balanced_accuracy_score(y_test, y_pred))\n",
    "\n",
    "    results.append({\n",
    "        'm': m,\n",
    "        'accuracy': np.mean(accs),\n",
    "        'balanced_accuracy': np.mean(bal_accs)\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nDeep Learning Results:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a4d597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
